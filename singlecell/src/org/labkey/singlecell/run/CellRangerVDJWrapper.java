package org.labkey.singlecell.run;

import au.com.bytecode.opencsv.CSVReader;
import org.apache.commons.io.FileUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.logging.log4j.Logger;
import org.jetbrains.annotations.Nullable;
import org.json.JSONObject;
import org.labkey.api.collections.CaseInsensitiveHashMap;
import org.labkey.api.data.CompareType;
import org.labkey.api.data.ConvertHelper;
import org.labkey.api.data.DbSchema;
import org.labkey.api.data.DbSchemaType;
import org.labkey.api.data.SimpleFilter;
import org.labkey.api.data.Table;
import org.labkey.api.data.TableInfo;
import org.labkey.api.data.TableSelector;
import org.labkey.api.pipeline.PipelineJob;
import org.labkey.api.pipeline.PipelineJobException;
import org.labkey.api.query.FieldKey;
import org.labkey.api.query.QueryService;
import org.labkey.api.query.UserSchema;
import org.labkey.api.reader.Readers;
import org.labkey.api.sequenceanalysis.RefNtSequenceModel;
import org.labkey.api.sequenceanalysis.SequenceOutputFile;
import org.labkey.api.sequenceanalysis.model.AnalysisModel;
import org.labkey.api.sequenceanalysis.model.ReadData;
import org.labkey.api.sequenceanalysis.model.Readset;
import org.labkey.api.sequenceanalysis.pipeline.AbstractAlignmentStepProvider;
import org.labkey.api.sequenceanalysis.pipeline.AlignerIndexUtil;
import org.labkey.api.sequenceanalysis.pipeline.AlignmentOutputImpl;
import org.labkey.api.sequenceanalysis.pipeline.AlignmentStep;
import org.labkey.api.sequenceanalysis.pipeline.AlignmentStepProvider;
import org.labkey.api.sequenceanalysis.pipeline.CommandLineParam;
import org.labkey.api.sequenceanalysis.pipeline.IndexOutputImpl;
import org.labkey.api.sequenceanalysis.pipeline.PipelineContext;
import org.labkey.api.sequenceanalysis.pipeline.ReferenceGenome;
import org.labkey.api.sequenceanalysis.pipeline.SequenceAnalysisJobSupport;
import org.labkey.api.sequenceanalysis.pipeline.SequencePipelineService;
import org.labkey.api.sequenceanalysis.pipeline.ToolParameterDescriptor;
import org.labkey.api.sequenceanalysis.run.AbstractAlignmentPipelineStep;
import org.labkey.api.sequenceanalysis.run.AbstractCommandWrapper;
import org.labkey.api.sequenceanalysis.run.SimpleScriptWrapper;
import org.labkey.api.util.FileUtil;
import org.labkey.api.util.PageFlowUtil;
import org.labkey.api.writer.PrintWriters;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.PrintWriter;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Date;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class CellRangerVDJWrapper extends AbstractCommandWrapper
{
    public CellRangerVDJWrapper(@Nullable Logger logger)
    {
        super(logger);
    }

    public static final String INNER_ENRICHMENT_PRIMERS = "innerEnrichmentPrimers";
    public static final String INCLUDE_GD = "includeGD";
    public static final String CHAIN = "chain";

    public static class VDJProvider extends AbstractAlignmentStepProvider<AlignmentStep>
    {
        public VDJProvider()
        {
            super("CellRanger VDJ", "Cell Ranger is an alignment/analysis pipeline specific to 10x genomic data, and this can only be used on fastqs generated by 10x.", Arrays.asList(
                    ToolParameterDescriptor.create("id", "Run ID Suffix", "If provided, this will be appended to the ID of this run (readset name will be first).", "textfield", new JSONObject(){{
                        put("allowBlank", true);
                    }}, null),
                    ToolParameterDescriptor.create(INNER_ENRICHMENT_PRIMERS, "Inner Enrichment Primers", "An option comma-separated list of the inner primers used for TCR enrichment. These will be used for trimming.", "textarea", new JSONObject(){{
                        put("height", 100);
                        put("width", 400);
                    }}, null),
                ), null, "https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger", true, false, false, ALIGNMENT_MODE.MERGE_THEN_ALIGN);
        }

        @Override
        public boolean shouldRunIdxstats()
        {
            return false;
        }

        @Override
        public String getName()
        {
            return "CellRanger-VDJ";
        }

        @Override
        public String getDescription()
        {
            return null;
        }

        @Override
        public AlignmentStep create(PipelineContext context)
        {
            return new CellRangerVDJAlignmentStep(this, context, new CellRangerVDJWrapper(context.getLogger()));
        }
    }

    private static final String LINEAGE_NUMBER_ADDITION = "999";

    public static class CellRangerVDJAlignmentStep extends AbstractAlignmentPipelineStep<CellRangerVDJWrapper> implements AlignmentStep
    {
        public CellRangerVDJAlignmentStep(AlignmentStepProvider<?> provider, PipelineContext ctx, CellRangerVDJWrapper wrapper)
        {
            super(provider, ctx, wrapper);
        }

        @Override
        public boolean supportsMetrics()
        {
            return false;
        }

        @Override
        public void init(SequenceAnalysisJobSupport support) throws PipelineJobException
        {
            ReferenceGenome referenceGenome = support.getCachedGenomes().iterator().next();
            boolean hasCachedIndex = AlignerIndexUtil.hasCachedIndex(this.getPipelineCtx(), getIndexCachedDirName(getPipelineCtx().getJob()), referenceGenome);
            if (!hasCachedIndex)
            {
                getPipelineCtx().getLogger().info("Creating FASTA for CellRanger VDJ Index for genome: " + referenceGenome.getName());
                File abFasta = getGenomeFasta(false);
                File gdFasta = getGenomeFasta(true);
                try (PrintWriter abWriter = PrintWriters.getPrintWriter(abFasta);PrintWriter gdWriter = PrintWriters.getPrintWriter(gdFasta))
                {
                    final AtomicInteger i = new AtomicInteger(0);
                    UserSchema us = QueryService.get().getUserSchema(getPipelineCtx().getJob().getUser(), getPipelineCtx().getJob().getContainer(), "sequenceanalysis");
                    List<Integer> seqIds = new TableSelector(us.getTable("reference_library_members", null), PageFlowUtil.set("ref_nt_id"), new SimpleFilter(FieldKey.fromString("library_id"), referenceGenome.getGenomeId()), null).getArrayList(Integer.class);
                    new TableSelector(us.getTable("ref_nt_sequences", null), new SimpleFilter(FieldKey.fromString("rowid"), seqIds, CompareType.IN), null).forEach(RefNtSequenceModel.class, nt -> {

                        if (nt.getLocus() == null)
                        {
                            throw new IllegalArgumentException("Locus was empty for NT with ID: " + nt.getRowid());
                        }

                        //NOTE: this allows dual TRA/TRD segments
                        String[] loci = nt.getLocus().split("[/,]");
                        for (String locus : loci)
                        {
                            i.getAndIncrement(); //cant use sequenceId since sequences might be represented multiple times across loci

                            String seq = nt.getSequence();

                            //example: >1|TRAV41*01 TRAV41|TRAV41|L-REGION+V-REGION|TR|TRA|None|None
                            //Note: for g/d recovery, add any gamma segments as TRA and delta as TRB. Also inject 99 into the segment number (i.e. TRDV1 -> TRBV1d and TRGJ2 -> TRAJ2g)
                            String name = nt.getName();
                            String lineage = nt.getLineage();

                            // Special-case TRAVxx/DVxx lineages:
                            if (lineage.startsWith("TRA") && lineage.contains("DV") && !lineage.contains("/DV"))
                            {
                                if (lineage.contains("-DV"))
                                {
                                    lineage = lineage.replace("-DV", "/DV");
                                }
                                else
                                {
                                    lineage = lineage.replace("DV", "/DV");
                                }
                            }

                            StringBuilder header = new StringBuilder();
                            header.append(">").append(i.get()).append("|").append(name).append(" ").append(lineage).append("|").append(lineage).append("|");

                            //translate into V_Region
                            String type;
                            if (nt.getLineage().contains("J"))
                            {
                                type = "J-REGION";
                            }
                            else if (nt.getLineage().contains("V"))
                            {
                                if (seq.length() < 300)
                                {
                                    getPipelineCtx().getLogger().info("V-segment too short, skipping: " + nt.getName() + " / " + nt.getSeqLength());
                                    continue;
                                }
                                else
                                {
                                    type = "L-REGION+V-REGION";
                                }
                            }
                            else if (nt.getLineage().contains("C"))
                            {
                                type = "C-REGION";
                            }
                            else if (nt.getLineage().contains("D"))
                            {
                                type = "D-REGION";
                            }
                            else
                            {
                                throw new RuntimeException("Unknown lineage: " + nt.getLineage());
                            }

                            header.append(type).append("|TR|").append(locus).append("|None|None");

                            if (
                                    "TRD".equals(locus) ||
                                    "TRG".equals(locus) ||
                                    // Add all TRAVs (which are not already tagged TRA/TRD) to the file:
                                    (nt.getLineage().contains("V") && "TRA".equals(nt.getLocus())))
                            {
                                gdWriter.write(header + "\n");
                                gdWriter.write(seq + "\n");
                            }

                            if (
                                    "TRA".equals(locus) ||
                                    "TRB".equals(locus) ||
                                    // Add all TRDVs (which are not already tagged TRA/TRD) to the file:
                                    (nt.getLineage().contains("V") && "TRD".equals(nt.getLocus())))
                            {
                                abWriter.write(header + "\n");
                                abWriter.write(seq + "\n");
                            }
                        }
                        nt.clearCachedSequence();
                    });
                }
                catch (IllegalArgumentException | IOException e)
                {
                    throw new PipelineJobException(e);
                }
            }
        }

        private File getGenomeFasta(boolean forGD)
        {
            return new File(getPipelineCtx().getSourceDirectory(), "cellRangerVDJ" + (forGD ? ".gd" : ".ab") + ".fasta");
        }

        @Override
        public String getIndexCachedDirName(PipelineJob job)
        {
            return getProvider().getName();
        }

        public String getIndexCachedDirName(PipelineJob job, boolean isGammaDelta)
        {
            return getIndexCachedDirName(job) + "-" + (isGammaDelta ? "gamma-delta" : "alpha-beta");
        }

        @Override
        public AlignmentStep.IndexOutput createIndex(ReferenceGenome referenceGenome, File outputDir) throws PipelineJobException
        {
            IndexOutputImpl output = new IndexOutputImpl(referenceGenome);

            // Repeat once for alpha/beta and once for gamma/delta
            for (String label : Arrays.asList("alpha-beta", "gamma-delta"))
            {
                boolean isGammaDelta = "gamma-delta".equals(label);
                File indexDir = new File(outputDir, getIndexCachedDirName(getPipelineCtx().getJob(), isGammaDelta));
                    boolean hasCachedIndex = AlignerIndexUtil.hasCachedIndex(this.getPipelineCtx(), getIndexCachedDirName(getPipelineCtx().getJob(), isGammaDelta), referenceGenome);
                if (hasCachedIndex)
                {
                    continue;
                }

                getPipelineCtx().getLogger().info("Creating CellRanger VDJ Index");
                getPipelineCtx().getLogger().info("using file: " + getGenomeFasta(isGammaDelta).getPath());
                output.addIntermediateFile(getGenomeFasta(isGammaDelta));

                //remove if directory exists
                if (indexDir.exists())
                {
                    try
                    {
                        FileUtils.deleteDirectory(indexDir);
                    }
                    catch (IOException e)
                    {
                        throw new PipelineJobException(e);
                    }
                }

                output.addInput(getGenomeFasta(isGammaDelta), "Input FASTA");

                List<String> args = new ArrayList<>();
                args.add(getWrapper().getExe().getPath());
                args.add("mkvdjref");
                args.add("--seqs=" + getGenomeFasta(isGammaDelta).getPath());
                args.add("--genome=" + indexDir.getName());

                getWrapper().setWorkingDir(indexDir.getParentFile());
                getWrapper().execute(args);

                output.appendOutputs(referenceGenome.getWorkingFastaFile(), indexDir);

                //recache if not already
                AlignerIndexUtil.saveCachedIndex(hasCachedIndex, getPipelineCtx(), indexDir, getIndexCachedDirName(getPipelineCtx().getJob(), isGammaDelta), referenceGenome);
            }

            return output;
        }

        @Override
        public boolean canAlignMultiplePairsAtOnce()
        {
            return true;
        }

        @Override
        public AlignmentStep.AlignmentOutput performAlignment(Readset rs, List<File> inputFastqs1, @Nullable List<File> inputFastqs2, File outputDirectory, ReferenceGenome referenceGenome, String basename, String readGroupId, @Nullable String platformUnit) throws PipelineJobException
        {
            AlignmentOutputImpl output = new AlignmentOutputImpl();

            // Repeat once for alpha/beta and once for gamma/delta
            for (String label : Arrays.asList("alpha-beta", "gamma-delta"))
            {
                boolean isGammaDelta = "gamma-delta".equals(label);

                List<String> args = new ArrayList<>();
                args.add(getWrapper().getExe().getPath());
                args.add("multi");

                String idParam = StringUtils.trimToNull(getProvider().getParameterByName("id").extractValue(getPipelineCtx().getJob(), getProvider(), getStepIdx(), String.class));
                String id = FileUtil.makeLegalName(rs.getName()) + (idParam == null ? "" : "-" + idParam);
                id = id.replaceAll("[^a-zA-z0-9_\\-]", "_");
                args.add("--id=" + id + (isGammaDelta ? "-gd" : "-ab"));

                File indexDir = AlignerIndexUtil.getIndexDir(referenceGenome, getIndexCachedDirName(getPipelineCtx().getJob(), isGammaDelta));
                String chainArg = getProvider().getParameterByName(CHAIN).extractValue(getPipelineCtx().getJob(), getProvider(), getStepIdx(), String.class);

                String primers = StringUtils.trimToNull(getProvider().getParameterByName(INNER_ENRICHMENT_PRIMERS).extractValue(getPipelineCtx().getJob(), getProvider(), getStepIdx(), String.class, null));
                File primerFile = new File(outputDirectory, "primers.txt");
                if (primers != null)
                {
                    primers = primers.replaceAll("\\s+", ",");
                    primers = primers.replaceAll(",+", ",");

                    try (PrintWriter writer = PrintWriters.getPrintWriter(primerFile))
                    {
                        Arrays.stream(primers.split(",")).forEach(x -> {
                            x = StringUtils.trimToNull(x);
                            if (x != null)
                            {
                                writer.println(x);
                            }
                        });
                    }
                    catch (IOException e)
                    {
                        throw new PipelineJobException(e);
                    }

                    output.addIntermediateFile(primerFile);
                }

                Integer maxThreads = SequencePipelineService.get().getMaxThreads(getPipelineCtx().getLogger());
                if (maxThreads != null)
                {
                    args.add("--localcores=" + maxThreads);
                }

                Integer maxRam = SequencePipelineService.get().getMaxRam();
                if (maxRam != null)
                {
                    args.add("--localmem=" + maxRam);
                }

                File localFqDir = new File(outputDirectory, "localFq");
                output.addIntermediateFile(localFqDir);
                Set<String> sampleNames = prepareFastqSymlinks(rs, localFqDir);

                getPipelineCtx().getLogger().debug("Sample names: [" + StringUtils.join(sampleNames, ",") + "]");

                File sampleFile = new File(getPipelineCtx().getWorkingDirectory(), "sample." + label + ".csv");
                output.addIntermediateFile(sampleFile);
                try (PrintWriter writer = PrintWriters.getPrintWriter(sampleFile))
                {
                    writer.println("[vdj]");
                    writer.println("reference," + indexDir.getPath());
                    writer.println("inner-enrichment-primers," + primerFile);
                    writer.println("create-bam,false");
                    writer.println("");
                    writer.println("[libraries]");
                    writer.println("fastq_id,fastqs,lanes,feature_types,subsample_rate");
                    for (String sampleName : sampleNames)
                    {
                        writer.println(sampleName + "," + localFqDir.getPath() + ",,VDJ-T" + (isGammaDelta ? "-GD" : "") + ",");
                    }
                }
                catch (IOException e)
                {
                    throw new PipelineJobException(e);
                }

                args.add("--csv=" + sampleFile.getPath());

                getWrapper().setWorkingDir(outputDirectory);

                //Note: we can safely assume only this server is working on these files, so if the _lock file exists, it was from a previous failed job.
                File lockFile = new File(outputDirectory, id + "/_lock");
                if (lockFile.exists())
                {
                    getPipelineCtx().getLogger().info("Lock file exists, deleting: " + lockFile.getPath());
                    lockFile.delete();
                }

                getWrapper().execute(args);

                File outdir = new File(outputDirectory, id);
                outdir = new File(outdir, "outs");

                File bam = new File(outdir, "all_contig.bam");
                if (!bam.exists())
                {
                    throw new PipelineJobException("Unable to find file: " + bam.getPath());
                }
                output.setBAM(bam);

                //now do cleanup/rename:
                try
                {
                    String fileSuffix = (isGammaDelta ? ".gd" : ".ab");
                    String prefix = FileUtil.makeLegalName(rs.getName() + fileSuffix + "_");
                    File outputHtml = new File(outdir, "web_summary.html");
                    if (!outputHtml.exists())
                    {
                        throw new PipelineJobException("Unable to find file: " + outputHtml.getPath());
                    }

                    File outputHtmlRename = new File(outdir, prefix + outputHtml.getName());
                    if (outputHtmlRename.exists())
                    {
                        outputHtmlRename.delete();
                    }
                    FileUtils.moveFile(outputHtml, outputHtmlRename);

                    output.addSequenceOutput(outputHtmlRename, rs.getName() + " 10x VDJ Summary", "10x Run Summary", rs.getRowId(), null, referenceGenome.getGenomeId(), null);

                    File outputVloupe = new File(outdir, "vloupe.vloupe");
                    File csv = new File(outdir, "all_contig_annotations.csv");
                    if (!outputVloupe.exists())
                    {
                        //NOTE: if there were no A/B hits, the vLoupe isnt created, but all other outputs exist
                        if (!csv.exists())
                        {
                            throw new PipelineJobException("Unable to find file: " + outputVloupe.getPath());
                        }
                    }
                    else
                    {
                        File outputVloupeRename = new File(outdir, prefix + outputVloupe.getName());
                        if (outputVloupeRename.exists())
                        {
                            outputVloupeRename.delete();
                        }
                        FileUtils.moveFile(outputVloupe, outputVloupeRename);
                        output.addSequenceOutput(outputVloupeRename, rs.getName() + " 10x VLoupe", "10x VLoupe", rs.getRowId(), null, referenceGenome.getGenomeId(), null);
                    }
                }
                catch (IOException e)
                {
                    throw new PipelineJobException(e);
                }

                //NOTE: this folder has many unnecessary files and symlinks that get corrupted when we rename the main outputs
                File directory = new File(outdir.getParentFile(), "SC_VDJ_ASSEMBLER_CS");
                if (directory.exists())
                {
                    //NOTE: this will have lots of symlinks, including corrupted ones, which java handles badly
                    new SimpleScriptWrapper(getPipelineCtx().getLogger()).execute(Arrays.asList("rm", "-Rf", directory.getPath()));
                }
                else
                {
                    getPipelineCtx().getLogger().warn("Unable to find folder: " + directory.getPath());
                }

                deleteSymlinks(localFqDir);
            }

            return output;
        }

        @Override
        public boolean doAddReadGroups()
        {
            return false;
        }

        @Override
        public boolean doSortIndexBam()
        {
            return false;
        }

        @Override
        public boolean alwaysCopyIndexToWorkingDir()
        {
            return false;
        }

        @Override
        public boolean supportsGzipFastqs()
        {
            return true;
        }

        private String getSymlinkFileName(String fileName, boolean doRename, String sampleName, int idx, boolean isReversed)
        {
            //NOTE: cellranger is very picky about file name formatting
            if (doRename)
            {
                sampleName = FileUtil.makeLegalName(sampleName.replaceAll("_", "-")).replaceAll(" ", "-").replaceAll("\\.", "-");
                return sampleName + "_S1_L001_R" + (isReversed ? "2" : "1") + "_" + StringUtils.leftPad(String.valueOf(idx), 3, "0") + ".fastq.gz";
            }
            else
            {
                Matcher m = FILE_PATTERN.matcher(fileName);
                if (m.matches())
                {
                    if (!StringUtils.isEmpty(m.group(7)))
                    {
                        return m.group(1).replaceAll("_", "-") + StringUtils.trimToEmpty(m.group(2)) + "_L" + StringUtils.trimToEmpty(m.group(3)) + "_" + StringUtils.trimToEmpty(m.group(4)) + StringUtils.trimToEmpty(m.group(5)) + StringUtils.trimToEmpty(m.group(6)) + ".fastq.gz";
                    }
                    else if (m.group(1).contains("_"))
                    {
                        getPipelineCtx().getLogger().info("replacing underscores in file/sample name");
                        return m.group(1).replaceAll("_", "-") + StringUtils.trimToEmpty(m.group(2)) + "_L" + StringUtils.trimToEmpty(m.group(3)) + "_" + StringUtils.trimToEmpty(m.group(4)) + StringUtils.trimToEmpty(m.group(5)) + StringUtils.trimToEmpty(m.group(6)) + ".fastq.gz";
                    }
                    else
                    {
                        getPipelineCtx().getLogger().info("no additional characters found");
                    }
                }
                else
                {
                    getPipelineCtx().getLogger().warn("filename does not match Illumina formatting: " + fileName);
                }
            }

            return FileUtil.makeLegalName(fileName);
        }

        public Set<String> prepareFastqSymlinks(Readset rs, File localFqDir) throws PipelineJobException
        {
            Set<String> ret = new HashSet<>();
            if (!localFqDir.exists())
            {
                localFqDir.mkdirs();
            }

            String[] files = localFqDir.list();
            if (files != null && files.length > 0)
            {
                deleteSymlinks(localFqDir);
            }

            int idx = 0;
            boolean doRename = true;  //cellranger is too picky - simply rename files all the time
            for (ReadData rd : rs.getReadData())
            {
                idx++;
                try
                {
                    File target1 = new File(localFqDir, getSymlinkFileName(rd.getFile1().getName(), doRename,  rs.getName(), idx, false));
                    getPipelineCtx().getLogger().debug("file: " + rd.getFile1().getPath());
                    getPipelineCtx().getLogger().debug("target: " + target1.getPath());
                    if (target1.exists())
                    {
                        getPipelineCtx().getLogger().debug("deleting existing symlink: " + target1.getName());
                        Files.delete(target1.toPath());
                    }

                    Files.createSymbolicLink(target1.toPath(), rd.getFile1().toPath());
                    ret.add(getSampleName(target1.getName()));

                    if (rd.getFile2() != null)
                    {
                        File target2 = new File(localFqDir, getSymlinkFileName(rd.getFile2().getName(), doRename, rs.getName(), idx, true));
                        getPipelineCtx().getLogger().debug("file: " + rd.getFile2().getPath());
                        getPipelineCtx().getLogger().debug("target: " + target2.getPath());
                        if (target2.exists())
                        {
                            getPipelineCtx().getLogger().debug("deleting existing symlink: " + target2.getName());
                            Files.delete(target2.toPath());
                        }
                        Files.createSymbolicLink(target2.toPath(), rd.getFile2().toPath());
                        ret.add(getSampleName(target2.getName()));
                    }
                }
                catch (IOException e)
                {
                    throw new PipelineJobException(e);
                }
            }

            return ret;
        }

        public void deleteSymlinks(File localFqDir) throws PipelineJobException
        {
            for (File fq : localFqDir.listFiles())
            {
                try
                {
                    getPipelineCtx().getLogger().debug("deleting symlink: " + fq.getName());
                    Files.delete(fq.toPath());
                }
                catch (IOException e)
                {
                    throw new PipelineJobException(e);
                }
            }
        }

        public void addMetrics(AnalysisModel model) throws PipelineJobException
        {
            getPipelineCtx().getLogger().debug("adding 10x metrics");

            File metrics = new File(model.getAlignmentFileObject().getParentFile(), "metrics_summary.csv");
            if (metrics.exists())
            {
                try (CSVReader reader = new CSVReader(Readers.getReader(metrics)))
                {
                    String[] line;
                    String[] header = null;
                    String[] metricValues = null;

                    int i = 0;
                    while ((line = reader.readNext()) != null)
                    {
                        if (i == 0)
                        {
                            header = line;
                        }
                        else
                        {
                            metricValues = line;
                            break;
                        }

                        i++;
                    }

                    if (model.getAlignmentFile() == null)
                    {
                        throw new PipelineJobException("model.getAlignmentFile() was null");
                    }

                    int totalAdded = 0;
                    TableInfo ti = DbSchema.get("sequenceanalysis", DbSchemaType.Module).getTable("quality_metrics");

                    //NOTE: if this job errored and restarted, we may have duplicate records:
                    SimpleFilter filter = new SimpleFilter(FieldKey.fromString("readset"), model.getReadset());
                    filter.addCondition(FieldKey.fromString("analysis_id"), model.getRowId(), CompareType.EQUAL);
                    filter.addCondition(FieldKey.fromString("dataid"), model.getAlignmentFile(), CompareType.EQUAL);
                    filter.addCondition(FieldKey.fromString("category"), "Cell Ranger VDJ", CompareType.EQUAL);
                    filter.addCondition(FieldKey.fromString("container"), getPipelineCtx().getJob().getContainer().getId(), CompareType.EQUAL);
                    TableSelector ts = new TableSelector(ti, PageFlowUtil.set("rowid"), filter, null);
                    if (ts.exists())
                    {
                        getPipelineCtx().getLogger().info("Deleting existing QC metrics (probably from prior restarted job)");
                        ts.getArrayList(Integer.class).forEach(rowid -> {
                            Table.delete(ti, rowid);
                        });
                    }

                    for (int j = 0; j < header.length; j++)
                    {
                        Map<String, Object> toInsert = new CaseInsensitiveHashMap<>();
                        toInsert.put("container", getPipelineCtx().getJob().getContainer().getId());
                        toInsert.put("createdby", getPipelineCtx().getJob().getUser().getUserId());
                        toInsert.put("created", new Date());
                        toInsert.put("readset", model.getReadset());
                        toInsert.put("analysis_id", model.getRowId());
                        toInsert.put("dataid", model.getAlignmentFile());

                        toInsert.put("category", "Cell Ranger VDJ");
                        toInsert.put("metricname", header[j]);

                        metricValues[j] = metricValues[j].replaceAll(",", "");
                        Object val = metricValues[j];
                        if (metricValues[j].contains("%"))
                        {
                            metricValues[j] = metricValues[j].replaceAll("%", "");
                            Double d = ConvertHelper.convert(metricValues[j], Double.class);
                            d = d / 100.0;
                            val = d;
                        }

                        toInsert.put("metricvalue", val);

                        Table.insert(getPipelineCtx().getJob().getUser(), ti, toInsert);
                        totalAdded++;
                    }

                    getPipelineCtx().getLogger().info("total metrics added: " + totalAdded);
                }
                catch (IOException e)
                {
                    throw new PipelineJobException(e);
                }
            }
            else
            {
                getPipelineCtx().getLogger().warn("unable to find metrics file: " + metrics.getPath());
            }
        }

        @Override
        public void complete(SequenceAnalysisJobSupport support, AnalysisModel model, Collection<SequenceOutputFile> outputFilesCreated) throws PipelineJobException
        {
            addMetrics(model);

            File bam = model.getAlignmentData().getFile();
            if (!bam.exists())
            {
                getPipelineCtx().getLogger().warn("BAM not found, expected: " + bam.getPath());
            }
        }

        private static final Pattern FILE_PATTERN = Pattern.compile("^(.+?)(_S[0-9]+){0,1}_L(.+?)_(R){0,1}([0-9])(_[0-9]+){0,1}(.*?)(\\.f(ast){0,1}q)(\\.gz)?$");
        private static final Pattern SAMPLE_PATTERN = Pattern.compile("^(.+)_S[0-9]+(.*)$");

        private String getSampleName(String fn)
        {
            Matcher matcher = FILE_PATTERN.matcher(fn);
            if (matcher.matches())
            {
                String ret = matcher.group(1);
                Matcher matcher2 = SAMPLE_PATTERN.matcher(ret);
                if (matcher2.matches())
                {
                    ret = matcher2.group(1);
                }
                else
                {
                    getPipelineCtx().getLogger().debug("_S not found in sample: [" + ret + "]");
                }

                ret = ret.replaceAll("_", "-");

                return ret;
            }
            else
            {
                getPipelineCtx().getLogger().debug("file does not match illumina pattern: [" + fn + "]");
            }

            throw new IllegalArgumentException("Unable to infer Illumina sample name: " + fn);
        }
    }

    protected File getExe()
    {
        return SequencePipelineService.get().getExeForPackage("CELLRANGERPATH", "cellranger");
    }
}
